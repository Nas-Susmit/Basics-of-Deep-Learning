# 📘 Understanding Neural Networks With Me

Welcome to Understanding Neural Networks With Me 🚀
This repo is a step-by-step implementation of a simple deep learning framework from scratch in Python + NumPy, without using high-level libraries like TensorFlow or PyTorch.

The goal is to learn by building: from data preprocessing, forward & backward propagation, regularization, optimization, all the way to decision boundaries and evaluation metrics.

# ⚡ Features Implemented

✔️ Data Loading & Preprocessing

Synthetic datasets (make_moons, make_circles, Gaussian blobs)

Train/dev/test splits

✔️ Neural Network Core

He initialization

Forward propagation (ReLU, Sigmoid)

Backward propagation

✔️ Gradient Checking

Compare analytical vs numerical gradients

✔️ Regularization

L2 regularization

Dropout

✔️ Optimization

Mini-batch gradient descent

Momentum

Adam optimizer

Learning rate decay schedules

✔️ Visualization

Decision boundaries with matplotlib

Loss curves

✔️ Evaluation Metrics

Accuracy, precision, recall, F1-score

Confusion matrix

# 🛠️ Installation & Setup

Clone the repo:

git clone https://github.com/YOUR-USERNAME/Basics-of-Deep-Learning.git
cd Basics-of-Deep-Learning


Install dependencies:

pip install -r requirements.txt


# Dependencies:

numpy

matplotlib

scikit-learn

# 🎯 Learning Outcomes

By the end of this project, you will:

Understand how neural networks learn from scratch

See the math behind forward & backward propagation

Implement regularization and optimization strategies

Visualize and evaluate models on toy datasets
